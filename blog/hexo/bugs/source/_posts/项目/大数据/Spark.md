---
title: 视频项目下的Spark
date: 2018-10-16 08:36:03
tags: [项目,spark]
categories: [项目]
---

### 1. 使用情况

#### 项目背景

项目主要是根据市场部所有数据来源作为数据源，将数据进行简单的ETL后的数据为市场部的数据参考。部分数据可以定制即市场部根据需要从其他系统或客户处获取相关数据。

数据经过业务人员的具体场景需要进行归并和聚合，并通过三方过滤系统对数据的属性进行分析和预测。

项目基于AWS的组件来完成相关数据的处理：

* S3: 存储csv或parquet的数据源文件
* EMR: 用于集群spark的任务
* Lambda: 用service less
* Athena: 用于查询S3中的数据

采用基于Scala的Spark程序进行计算，通过Apache-Airflow进行调度

InBound：

OutBound：

#### 数据情况

总体上将数据根据其服务分为now和go两个大的分支，因为来源数据的规则不同导致2个数据的处理过程有一定的差别，但是具体的处理流程大体相同和相似。数据的格式稍有不同。

根据视频流的特点进行数据节点的划分: stream -> asset -> season -> series -> summary -> report

由于历史原因now数据的源会每天更新前7到14天的相关数据，导致每次需要处理的数据为当天及前7天的数据，因为每次数据需要从最前7天开始处理，故而导致数据量大而多。主要会重新处理asset之前的数据，这段确实是数据量最大的。

而go的数据源为后来更新和处理的，故而每天只为当天的数据量。相对来说处理比较简单，但是数据量还是很大。

#### 实际效果

### 2. 可以改进

### 3. 总结
